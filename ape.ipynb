{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talhão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.metrics import MeanAbsolutePercentageError, RootMeanSquaredError, MeanSquaredError, MeanAbsoluteError\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import MeanAbsoluteError\n",
    "from keras.metrics import MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "def divide_into_parts(df, lat_col, lon_col, N):\n",
    "    \"\"\"\n",
    "    Divide a DataFrame into N parts based on latitude and longitude.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to be divided.\n",
    "        lat_col (str): Column name for latitude.\n",
    "        lon_col (str): Column name for longitude.\n",
    "        N (int): Number of parts to divide the DataFrame into.\n",
    "\n",
    "    Returns:\n",
    "        list: List of DataFrames representing each part.\n",
    "    \"\"\"\n",
    "    # Check if N is a valid positive integer\n",
    "    if N <= 0:\n",
    "        raise ValueError(\"N must be a positive integer.\")\n",
    "\n",
    "    # Sort the DataFrame based on latitude and longitude columns\n",
    "    df_sorted = df.sort_values(by=[lat_col, lon_col])\n",
    "\n",
    "    # Calculate the number of samples in each part\n",
    "    num_samples = len(df_sorted)\n",
    "    samples_per_part = num_samples // N\n",
    "    remainder = num_samples % N\n",
    "\n",
    "    parts = []\n",
    "\n",
    "    # Divide the DataFrame into N parts\n",
    "    start_idx = 0\n",
    "    for i in range(N):\n",
    "        end_idx = start_idx + samples_per_part + (1 if i < remainder else 0)\n",
    "        current_part = df_sorted.iloc[start_idx:end_idx]\n",
    "        parts.append(current_part)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return parts\n",
    "\n",
    "def combine_parts(part_list):\n",
    "    \"\"\"\n",
    "    Combine a list of DataFrames into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        quadrant_list (list): List of DataFrames to be combined.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame.\n",
    "    \"\"\"\n",
    "    # Check if at least one DataFrame is provided\n",
    "    if not part_list or len(part_list) < 2:\n",
    "        raise ValueError(\"At least two DataFrames are required for combination.\")\n",
    "\n",
    "    # Combine all DataFrames in the list into a single DataFrame\n",
    "    combined_df = pd.concat(part_list, ignore_index=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def kfold_ape(X, Y, model_type='linear', k=4, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform k-fold Absolute Percentage Error (APE) evaluation for regression models.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature DataFrame.\n",
    "        Y (pd.DataFrame): Target DataFrame.\n",
    "        model_type (str): Type of regression model ('linear', 'random_forest', or 'keras').\n",
    "        k (int): Number of folds for k-fold cross-validation.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing APE values for each target column and each fold.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store results\n",
    "    target_names = []\n",
    "    ape_values = []\n",
    "\n",
    "    # Normalize the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Apply PCA with 5 components\n",
    "    pca = PCA(n_components=5)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=k, shuffle=False)\n",
    "\n",
    "    # Initialize the final DataFrame to store APEs for all folds\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    # Choose the training model\n",
    "    if model_type == 'keras':\n",
    "        input_neurons = X_pca.shape[1]  # Number of features after PCA\n",
    "        output_neurons = Y.shape[1]  # Number of target columns\n",
    "        model = build_simple_neural_network(input_neurons, output_neurons)\n",
    "\n",
    "        # Iterate over folds\n",
    "        for train_index, test_index in kf.split(X_pca):\n",
    "            X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "            y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "            # Prediction on the test set\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate APE for each point in the test set\n",
    "            fold_errors = np.abs(y_test - y_test_pred) / np.abs(y_test)\n",
    "\n",
    "            # Concatenate errors for all targets\n",
    "            if result_df.empty:\n",
    "                result_df = pd.DataFrame(fold_errors, columns=Y.columns)\n",
    "            else:\n",
    "                result_df = pd.concat([result_df, pd.DataFrame(fold_errors, columns=Y.columns)], ignore_index=True)\n",
    "\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "        # Iterate over target columns (Y)\n",
    "        for target_column in Y.columns:\n",
    "            target_errors = []  # To store errors for each fold\n",
    "\n",
    "            # Iterate over folds\n",
    "            for train_index, test_index in kf.split(X_pca):\n",
    "                X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "                y_train, y_test = Y.iloc[train_index][target_column], Y.iloc[test_index][target_column]\n",
    "\n",
    "                # Train the model\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Prediction on the test set\n",
    "                y_test_pred = model.predict(X_test)\n",
    "\n",
    "                # Calculate APE for each point in the test set\n",
    "                fold_errors = abs(y_test - y_test_pred) / abs(y_test)\n",
    "                target_errors.extend(fold_errors)\n",
    "\n",
    "            # Add target column and errors for this column to the final DataFrame\n",
    "            result_df[target_column] = target_errors\n",
    "\n",
    "    elif model_type == 'linear':\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # Iterate over target columns (Y)\n",
    "        for target_column in Y.columns:\n",
    "            target_errors = []  # To store errors for each fold\n",
    "\n",
    "            # Iterate over folds\n",
    "            for train_index, test_index in kf.split(X_pca):\n",
    "                X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "                y_train, y_test = Y.iloc[train_index][target_column], Y.iloc[test_index][target_column]\n",
    "\n",
    "                # Train the model\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Prediction on the test set\n",
    "                y_test_pred = model.predict(X_test)\n",
    "\n",
    "                # Calculate APE for each point in the test set\n",
    "                fold_errors = abs(y_test - y_test_pred) / abs(y_test)\n",
    "                target_errors.extend(fold_errors)\n",
    "\n",
    "            # Add target column and errors for this column to the final DataFrame\n",
    "            result_df[target_column] = target_errors\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def build_simple_neural_network(input_neurons, output_neurons, optimizer='adam', loss='mse'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Adicionando a camada de entrada\n",
    "    model.add(Dense(input_neurons, input_dim=input_neurons, activation='relu'))\n",
    "    \n",
    "    # Adicionando a camada oculta com o mesmo número de neurônios da camada de entrada\n",
    "    model.add(Dense(input_neurons, activation='relu'))\n",
    "    \n",
    "    # Adicionando a camada de saída\n",
    "    model.add(Dense(output_neurons, activation='linear'))  # Utilize 'linear' se for um problema de regressão\n",
    "    \n",
    "    # Compilando o modelo\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[MeanSquaredError()])\n",
    "    \n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "map1_df = pd.read_csv('data/map1/interpolation/nearest_neighbors_interpolation_df.csv')\n",
    "slices = divide_into_parts(map1_df, 'latitude', 'longitude', 10)\n",
    "combined_slices = combine_parts(slices)\n",
    "\n",
    "X = combined_slices.iloc[:, :15]\n",
    "X = X.drop(['latitude', 'longitude'], axis=1)\n",
    "y = combined_slices.iloc[:, 15:]\n",
    "\n",
    "# Perform k-fold APE evaluation for Linear Regression, Random Forest and Keras\n",
    "map1_linear_regression_error = kfold_ape(X, y, model_type='linear', k=10)\n",
    "map1_random_forest_error = kfold_ape(X, y, model_type='random_forest', k=10)\n",
    "map1_keras_error = kfold_ape(X, y, model_type='keras', k=10)\n",
    "\n",
    "# Save the results to CSV files\n",
    "map1_linear_regression_error.to_csv('data/map1/errors/linear_regression_error.csv')\n",
    "map1_random_forest_error.to_csv('data/map1/errors/random_forest_error.csv')\n",
    "map1_keras_error.to_csv('data/map1/errors/keras_error.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talhão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "map2_df = pd.read_csv('data/map2/interpolation/nearest_neighbors_interpolation_df.csv')\n",
    "slices = divide_into_parts(map2_df, 'latitude', 'longitude', 10)\n",
    "combined_slices = combine_parts(slices)\n",
    "\n",
    "X = combined_slices.iloc[:, :14]\n",
    "X = X.drop(['latitude', 'longitude'], axis=1)\n",
    "y = combined_slices.iloc[:, 14:]\n",
    "\n",
    "# Perform k-fold APE evaluation for Linear Regression, Random Forest and Keras\n",
    "map2_linear_regression_error = kfold_ape(X, y, model_type='linear', k=10)\n",
    "map2_random_forest_error = kfold_ape(X, y, model_type='random_forest', k=10)\n",
    "map2_keras_error = kfold_ape(X, y, model_type='keras', k=10)\n",
    "\n",
    "# Save the results to CSV files\n",
    "map2_linear_regression_error.to_csv('data/map2/errors/linear_regression_error.csv')\n",
    "map2_random_forest_error.to_csv('data/map2/errors/random_forest_error.csv')\n",
    "map2_keras_error.to_csv('data/map2/errors/keras_error.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
